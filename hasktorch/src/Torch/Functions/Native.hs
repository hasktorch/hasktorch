
-- generated by using spec/Declarations.yaml

{-# LANGUAGE DataKinds #-}
{-# LANGUAGE PolyKinds #-}
{-# LANGUAGE TemplateHaskell #-}
{-# LANGUAGE QuasiQuotes #-}
{-# LANGUAGE ScopedTypeVariables #-}
{-# LANGUAGE OverloadedStrings #-}

module Torch.Functions.Native where


import System.IO.Unsafe
import Foreign.ForeignPtr

import qualified ATen.Managed.Native as ATen
import qualified ATen.Managed.Type.Tensor as ATen
import qualified ATen.Managed.Type.Scalar as ATen
import qualified ATen.Managed.Type.Tuple as ATen
import qualified ATen.Const as ATen
import qualified ATen.Type as ATen
import qualified ATen.Managed.Cast
import ATen.Cast

import Torch.Tensor
import Torch.Scalar
import Torch.Cast


dropout :: Tensor -> Double -> Bool -> Tensor
dropout _input _p _train = unsafePerformIO $ (cast3 ATen.dropout_tdb) _input _p _train

feature_dropout :: Tensor -> Double -> Bool -> Tensor
feature_dropout _input _p _train = unsafePerformIO $ (cast3 ATen.feature_dropout_tdb) _input _p _train

alpha_dropout :: Tensor -> Double -> Bool -> Tensor
alpha_dropout _input _p _train = unsafePerformIO $ (cast3 ATen.alpha_dropout_tdb) _input _p _train

feature_alpha_dropout :: Tensor -> Double -> Bool -> Tensor
feature_alpha_dropout _input _p _train = unsafePerformIO $ (cast3 ATen.feature_alpha_dropout_tdb) _input _p _train

acos :: Tensor -> Tensor
acos _self = unsafePerformIO $ (cast1 ATen.acos_t) _self

avg_pool1d :: Tensor -> Int -> Int -> Int -> Bool -> Bool -> Tensor
avg_pool1d _self _kernel_size _stride _padding _ceil_mode _count_include_pad = unsafePerformIO $ (cast6 ATen.avg_pool1d_tlllbb) _self _kernel_size _stride _padding _ceil_mode _count_include_pad

adaptive_avg_pool1d :: Tensor -> Int -> Tensor
adaptive_avg_pool1d _self _output_size = unsafePerformIO $ (cast2 ATen.adaptive_avg_pool1d_tl) _self _output_size

adaptive_max_pool1d :: Tensor -> Int -> (Tensor,Tensor)
adaptive_max_pool1d _self _output_size = unsafePerformIO $ (cast2 ATen.adaptive_max_pool1d_tl) _self _output_size

addmv :: Tensor -> Tensor -> Tensor -> Float -> Float -> Tensor
addmv _self _mat _vec _beta _alpha = unsafePerformIO $ (cast5 ATen.addmv_tttss) _self _mat _vec _beta _alpha

addr :: Tensor -> Tensor -> Tensor -> Float -> Float -> Tensor
addr _self _vec1 _vec2 _beta _alpha = unsafePerformIO $ (cast5 ATen.addr_tttss) _self _vec1 _vec2 _beta _alpha

affine_grid_generator :: Tensor -> [Int] -> Tensor
affine_grid_generator _theta _size = unsafePerformIO $ (cast2 ATen.affine_grid_generator_tl) _theta _size

affine_grid_generator_backward :: Tensor -> [Int] -> Tensor
affine_grid_generator_backward _grad _size = unsafePerformIO $ (cast2 ATen.affine_grid_generator_backward_tl) _grad _size

allclose :: Tensor -> Tensor -> Double -> Double -> Bool -> Bool
allclose _self _other _rtol _atol _equal_nan = unsafePerformIO $ (cast5 ATen.allclose_ttddb) _self _other _rtol _atol _equal_nan

argmax :: Tensor -> Int -> Bool -> Tensor
argmax _self _dim _keepdim = unsafePerformIO $ (cast3 ATen.argmax_tlb) _self _dim _keepdim

argmin :: Tensor -> Int -> Bool -> Tensor
argmin _self _dim _keepdim = unsafePerformIO $ (cast3 ATen.argmin_tlb) _self _dim _keepdim

as_strided :: Tensor -> [Int] -> [Int] -> Int -> Tensor
as_strided _self _size _stride _storage_offset = unsafePerformIO $ (cast4 ATen.as_strided_tlll) _self _size _stride _storage_offset

asin :: Tensor -> Tensor
asin _self = unsafePerformIO $ (cast1 ATen.asin_t) _self

atan :: Tensor -> Tensor
atan _self = unsafePerformIO $ (cast1 ATen.atan_t) _self

baddbmm :: Tensor -> Tensor -> Tensor -> Float -> Float -> Tensor
baddbmm _self _batch1 _batch2 _beta _alpha = unsafePerformIO $ (cast5 ATen.baddbmm_tttss) _self _batch1 _batch2 _beta _alpha

batch_norm :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Bool -> Double -> Double -> Bool -> Tensor
batch_norm _input _weight _bias _running_mean _running_var _training _momentum _eps _cudnn_enabled = unsafePerformIO $ (cast9 ATen.batch_norm_tttttbddb) _input _weight _bias _running_mean _running_var _training _momentum _eps _cudnn_enabled

bilinear :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor
bilinear _input1 _input2 _weight _bias = unsafePerformIO $ (cast4 ATen.bilinear_tttt) _input1 _input2 _weight _bias

binary_cross_entropy_with_logits :: Tensor -> Tensor -> Tensor -> Tensor -> Int -> Tensor
binary_cross_entropy_with_logits _self _target _weight _pos_weight _reduction = unsafePerformIO $ (cast5 ATen.binary_cross_entropy_with_logits_ttttl) _self _target _weight _pos_weight _reduction

binary_cross_entropy_with_logits_backward :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Int -> Tensor
binary_cross_entropy_with_logits_backward _grad_output _self _target _weight _pos_weight _reduction = unsafePerformIO $ (cast6 ATen.binary_cross_entropy_with_logits_backward_tttttl) _grad_output _self _target _weight _pos_weight _reduction

bincount :: Tensor -> Tensor -> Int -> Tensor
bincount _self _weights _minlength = unsafePerformIO $ (cast3 ATen.bincount_ttl) _self _weights _minlength

bitwise_not :: Tensor -> Tensor
bitwise_not _self = unsafePerformIO $ (cast1 ATen.bitwise_not_t) _self

bmm :: Tensor -> Tensor -> Tensor
bmm _self _mat2 = unsafePerformIO $ (cast2 ATen.bmm_tt) _self _mat2

broadcast_tensors :: [Tensor] -> [Tensor]
broadcast_tensors _tensors = unsafePerformIO $ (cast1 ATen.broadcast_tensors_l) _tensors

cat :: [Tensor] -> Int -> Tensor
cat _tensors _dim = unsafePerformIO $ (cast2 ATen.cat_ll) _tensors _dim

chain_matmul :: [Tensor] -> Tensor
chain_matmul _matrices = unsafePerformIO $ (cast1 ATen.chain_matmul_l) _matrices

chunk :: Tensor -> Int -> Int -> [Tensor]
chunk _self _chunks _dim = unsafePerformIO $ (cast3 ATen.chunk_tll) _self _chunks _dim

clamp :: Tensor -> Float -> Float -> Tensor
clamp _self _min _max = unsafePerformIO $ (cast3 ATen.clamp_tss) _self _min _max

clamp_max :: Tensor -> Float -> Tensor
clamp_max _self _max = unsafePerformIO $ (cast2 ATen.clamp_max_ts) _self _max

clamp_min :: Tensor -> Float -> Tensor
clamp_min _self _min = unsafePerformIO $ (cast2 ATen.clamp_min_ts) _self _min

cudnn_is_acceptable :: Tensor -> Bool
cudnn_is_acceptable _self = unsafePerformIO $ (cast1 ATen.cudnn_is_acceptable_t) _self

constant_pad_nd :: Tensor -> [Int] -> Float -> Tensor
constant_pad_nd _self _pad _value = unsafePerformIO $ (cast3 ATen.constant_pad_nd_tls) _self _pad _value

convolution :: Tensor -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Bool -> [Int] -> Int -> Tensor
convolution _input _weight _bias _stride _padding _dilation _transposed _output_padding _groups = unsafePerformIO $ (cast9 ATen.convolution_tttlllbll) _input _weight _bias _stride _padding _dilation _transposed _output_padding _groups

conv1d :: Tensor -> Tensor -> Tensor -> Int -> Int -> Int -> Int -> Tensor
conv1d _input _weight _bias _stride _padding _dilation _groups = unsafePerformIO $ (cast7 ATen.conv1d_tttllll) _input _weight _bias _stride _padding _dilation _groups

conv3d :: Tensor -> Tensor -> Tensor -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> Int -> Tensor
conv3d _input _weight _bias _stride _padding _dilation _groups = unsafePerformIO $ (cast7 ATen.conv3d_tttllll) _input _weight _bias _stride _padding _dilation _groups

conv_tbc :: Tensor -> Tensor -> Tensor -> Int -> Tensor
conv_tbc _self _weight _bias _pad = unsafePerformIO $ (cast4 ATen.conv_tbc_tttl) _self _weight _bias _pad

conv_tbc_backward :: Tensor -> Tensor -> Tensor -> Tensor -> Int -> (Tensor,Tensor,Tensor)
conv_tbc_backward _self _input _weight _bias _pad = unsafePerformIO $ (cast5 ATen.conv_tbc_backward_ttttl) _self _input _weight _bias _pad

conv_transpose1d :: Tensor -> Tensor -> Tensor -> Int -> Int -> Int -> Int -> Int -> Tensor
conv_transpose1d _input _weight _bias _stride _padding _output_padding _groups _dilation = unsafePerformIO $ (cast8 ATen.conv_transpose1d_tttlllll) _input _weight _bias _stride _padding _output_padding _groups _dilation

cosh :: Tensor -> Tensor
cosh _self = unsafePerformIO $ (cast1 ATen.cosh_t) _self

cosine_embedding_loss :: Tensor -> Tensor -> Tensor -> Double -> Int -> Tensor
cosine_embedding_loss _input1 _input2 _target _margin _reduction = unsafePerformIO $ (cast5 ATen.cosine_embedding_loss_tttdl) _input1 _input2 _target _margin _reduction

cudnn_affine_grid_generator :: Tensor -> Int -> Int -> Int -> Int -> Tensor
cudnn_affine_grid_generator _theta _N _C _H _W = unsafePerformIO $ (cast5 ATen.cudnn_affine_grid_generator_tllll) _theta _N _C _H _W

cudnn_affine_grid_generator_backward :: Tensor -> Int -> Int -> Int -> Int -> Tensor
cudnn_affine_grid_generator_backward _grad _N _C _H _W = unsafePerformIO $ (cast5 ATen.cudnn_affine_grid_generator_backward_tllll) _grad _N _C _H _W

cudnn_batch_norm :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Bool -> Double -> Double -> (Tensor,Tensor,Tensor)
cudnn_batch_norm _input _weight _bias _running_mean _running_var _training _exponential_average_factor _epsilon = unsafePerformIO $ (cast8 ATen.cudnn_batch_norm_tttttbdd) _input _weight _bias _running_mean _running_var _training _exponential_average_factor _epsilon

cudnn_batch_norm_backward :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Double -> (Tensor,Tensor,Tensor)
cudnn_batch_norm_backward _input _grad_output _weight _running_mean _running_var _save_mean _save_var _epsilon = unsafePerformIO $ (cast8 ATen.cudnn_batch_norm_backward_tttttttd) _input _grad_output _weight _running_mean _running_var _save_mean _save_var _epsilon

cudnn_convolution :: Tensor -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> Tensor
cudnn_convolution _self _weight _bias _padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (cast9 ATen.cudnn_convolution_tttllllbb) _self _weight _bias _padding _stride _dilation _groups _benchmark _deterministic

cudnn_convolution_backward_input :: [Int] -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> Tensor
cudnn_convolution_backward_input _self_size _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (cast9 ATen.cudnn_convolution_backward_input_lttllllbb) _self_size _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic

cudnn_convolution_backward :: Tensor -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> (Bool,Bool,Bool) -> (Tensor,Tensor,Tensor)
cudnn_convolution_backward _self _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic _output_mask = unsafePerformIO $ (cast10 ATen.cudnn_convolution_backward_tttllllbba) _self _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic _output_mask

cudnn_convolution_backward_bias :: Tensor -> Tensor
cudnn_convolution_backward_bias _grad_output = unsafePerformIO $ (cast1 ATen.cudnn_convolution_backward_bias_t) _grad_output

cudnn_convolution_backward_weight :: [Int] -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> Tensor
cudnn_convolution_backward_weight _weight_size _grad_output _self _padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (cast9 ATen.cudnn_convolution_backward_weight_lttllllbb) _weight_size _grad_output _self _padding _stride _dilation _groups _benchmark _deterministic

cudnn_convolution_transpose :: Tensor -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> Tensor
cudnn_convolution_transpose _self _weight _bias _padding _output_padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (cast10 ATen.cudnn_convolution_transpose_tttlllllbb) _self _weight _bias _padding _output_padding _stride _dilation _groups _benchmark _deterministic

cudnn_convolution_transpose_backward :: Tensor -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> (Bool,Bool,Bool) -> (Tensor,Tensor,Tensor)
cudnn_convolution_transpose_backward _self _grad_output _weight _padding _output_padding _stride _dilation _groups _benchmark _deterministic _output_mask = unsafePerformIO $ (cast11 ATen.cudnn_convolution_transpose_backward_tttlllllbba) _self _grad_output _weight _padding _output_padding _stride _dilation _groups _benchmark _deterministic _output_mask

cudnn_convolution_transpose_backward_bias :: Tensor -> Tensor
cudnn_convolution_transpose_backward_bias _grad_output = unsafePerformIO $ (cast1 ATen.cudnn_convolution_transpose_backward_bias_t) _grad_output

cudnn_convolution_transpose_backward_input :: Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> Tensor
cudnn_convolution_transpose_backward_input _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (cast8 ATen.cudnn_convolution_transpose_backward_input_ttllllbb) _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic

cudnn_convolution_transpose_backward_weight :: [Int] -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> Tensor
cudnn_convolution_transpose_backward_weight _weight_size _grad_output _self _padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (cast9 ATen.cudnn_convolution_transpose_backward_weight_lttllllbb) _weight_size _grad_output _self _padding _stride _dilation _groups _benchmark _deterministic

cudnn_grid_sampler :: Tensor -> Tensor -> Tensor
cudnn_grid_sampler _self _grid = unsafePerformIO $ (cast2 ATen.cudnn_grid_sampler_tt) _self _grid

cudnn_grid_sampler_backward :: Tensor -> Tensor -> Tensor -> (Tensor,Tensor)
cudnn_grid_sampler_backward _self _grid _grad_output = unsafePerformIO $ (cast3 ATen.cudnn_grid_sampler_backward_ttt) _self _grid _grad_output

det :: Tensor -> Tensor
det _self = unsafePerformIO $ (cast1 ATen.det_t) _self

diag_embed :: Tensor -> Int -> Int -> Int -> Tensor
diag_embed _self _offset _dim1 _dim2 = unsafePerformIO $ (cast4 ATen.diag_embed_tlll) _self _offset _dim1 _dim2

diagflat :: Tensor -> Int -> Tensor
diagflat _self _offset = unsafePerformIO $ (cast2 ATen.diagflat_tl) _self _offset

diagonal :: Tensor -> Int -> Int -> Int -> Tensor
diagonal _self _offset _dim1 _dim2 = unsafePerformIO $ (cast4 ATen.diagonal_tlll) _self _offset _dim1 _dim2

dot :: Tensor -> Tensor -> Tensor
dot _self _tensor = unsafePerformIO $ (cast2 ATen.dot_tt) _self _tensor

einsum :: String -> [Tensor] -> Tensor
einsum _equation _tensors = unsafePerformIO $ (cast2 ATen.einsum_sl) _equation _tensors

embedding :: Tensor -> Tensor -> Int -> Bool -> Bool -> Tensor
embedding _weight _indices _padding_idx _scale_grad_by_freq _sparse = unsafePerformIO $ (cast5 ATen.embedding_ttlbb) _weight _indices _padding_idx _scale_grad_by_freq _sparse

embedding_backward :: Tensor -> Tensor -> Int -> Int -> Bool -> Bool -> Tensor
embedding_backward _grad _indices _num_weights _padding_idx _scale_grad_by_freq _sparse = unsafePerformIO $ (cast6 ATen.embedding_backward_ttllbb) _grad _indices _num_weights _padding_idx _scale_grad_by_freq _sparse

embedding_dense_backward :: Tensor -> Tensor -> Int -> Int -> Bool -> Tensor
embedding_dense_backward _grad_output _indices _num_weights _padding_idx _scale_grad_by_freq = unsafePerformIO $ (cast5 ATen.embedding_dense_backward_ttllb) _grad_output _indices _num_weights _padding_idx _scale_grad_by_freq

embedding_sparse_backward :: Tensor -> Tensor -> Int -> Int -> Bool -> Tensor
embedding_sparse_backward _grad _indices _num_weights _padding_idx _scale_grad_by_freq = unsafePerformIO $ (cast5 ATen.embedding_sparse_backward_ttllb) _grad _indices _num_weights _padding_idx _scale_grad_by_freq

embedding_bag :: Tensor -> Tensor -> Tensor -> Bool -> Int -> Bool -> Tensor -> (Tensor,Tensor,Tensor,Tensor)
embedding_bag _weight _indices _offsets _scale_grad_by_freq _mode _sparse _per_sample_weights = unsafePerformIO $ (cast7 ATen.embedding_bag_tttblbt) _weight _indices _offsets _scale_grad_by_freq _mode _sparse _per_sample_weights

empty_like :: Tensor -> Tensor
empty_like _self = unsafePerformIO $ (cast1 ATen.empty_like_t) _self

erfc :: Tensor -> Tensor
erfc _self = unsafePerformIO $ (cast1 ATen.erfc_t) _self

expm1 :: Tensor -> Tensor
expm1 _self = unsafePerformIO $ (cast1 ATen.expm1_t) _self

flatten :: Tensor -> Int -> Int -> Tensor
flatten _self _start_dim _end_dim = unsafePerformIO $ (cast3 ATen.flatten_tll) _self _start_dim _end_dim

frac :: Tensor -> Tensor
frac _self = unsafePerformIO $ (cast1 ATen.frac_t) _self

full_like :: Tensor -> Float -> Tensor
full_like _self _fill_value = unsafePerformIO $ (cast2 ATen.full_like_ts) _self _fill_value

grid_sampler :: Tensor -> Tensor -> Int -> Int -> Tensor
grid_sampler _input _grid _interpolation_mode _padding_mode = unsafePerformIO $ (cast4 ATen.grid_sampler_ttll) _input _grid _interpolation_mode _padding_mode

grid_sampler_2d :: Tensor -> Tensor -> Int -> Int -> Tensor
grid_sampler_2d _input _grid _interpolation_mode _padding_mode = unsafePerformIO $ (cast4 ATen.grid_sampler_2d_ttll) _input _grid _interpolation_mode _padding_mode

grid_sampler_2d_backward :: Tensor -> Tensor -> Tensor -> Int -> Int -> (Tensor,Tensor)
grid_sampler_2d_backward _grad_output _input _grid _interpolation_mode _padding_mode = unsafePerformIO $ (cast5 ATen.grid_sampler_2d_backward_tttll) _grad_output _input _grid _interpolation_mode _padding_mode

grid_sampler_3d :: Tensor -> Tensor -> Int -> Int -> Tensor
grid_sampler_3d _input _grid _interpolation_mode _padding_mode = unsafePerformIO $ (cast4 ATen.grid_sampler_3d_ttll) _input _grid _interpolation_mode _padding_mode

grid_sampler_3d_backward :: Tensor -> Tensor -> Tensor -> Int -> Int -> (Tensor,Tensor)
grid_sampler_3d_backward _grad_output _input _grid _interpolation_mode _padding_mode = unsafePerformIO $ (cast5 ATen.grid_sampler_3d_backward_tttll) _grad_output _input _grid _interpolation_mode _padding_mode

hinge_embedding_loss :: Tensor -> Tensor -> Double -> Int -> Tensor
hinge_embedding_loss _self _target _margin _reduction = unsafePerformIO $ (cast4 ATen.hinge_embedding_loss_ttdl) _self _target _margin _reduction

ger :: Tensor -> Tensor -> Tensor
ger _self _vec2 = unsafePerformIO $ (cast2 ATen.ger_tt) _self _vec2

group_norm :: Tensor -> Int -> Tensor -> Tensor -> Double -> Bool -> Tensor
group_norm _input _num_groups _weight _bias _eps _cudnn_enabled = unsafePerformIO $ (cast6 ATen.group_norm_tlttdb) _input _num_groups _weight _bias _eps _cudnn_enabled

fft :: Tensor -> Int -> Bool -> Tensor
fft _self _signal_ndim _normalized = unsafePerformIO $ (cast3 ATen.fft_tlb) _self _signal_ndim _normalized

ifft :: Tensor -> Int -> Bool -> Tensor
ifft _self _signal_ndim _normalized = unsafePerformIO $ (cast3 ATen.ifft_tlb) _self _signal_ndim _normalized

rfft :: Tensor -> Int -> Bool -> Bool -> Tensor
rfft _self _signal_ndim _normalized _onesided = unsafePerformIO $ (cast4 ATen.rfft_tlbb) _self _signal_ndim _normalized _onesided

irfft :: Tensor -> Int -> Bool -> Bool -> [Int] -> Tensor
irfft _self _signal_ndim _normalized _onesided _signal_sizes = unsafePerformIO $ (cast5 ATen.irfft_tlbbl) _self _signal_ndim _normalized _onesided _signal_sizes

index :: Tensor -> [Tensor] -> Tensor
index _self _indices = unsafePerformIO $ (cast2 ATen.index_tl) _self _indices

index_copy :: Tensor -> Int -> Tensor -> Tensor -> Tensor
index_copy _self _dim _index _source = unsafePerformIO $ (cast4 ATen.index_copy_tltt) _self _dim _index _source

index_put :: Tensor -> [Tensor] -> Tensor -> Bool -> Tensor
index_put _self _indices _values _accumulate = unsafePerformIO $ (cast4 ATen.index_put_tltb) _self _indices _values _accumulate

instance_norm :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Bool -> Double -> Double -> Bool -> Tensor
instance_norm _input _weight _bias _running_mean _running_var _use_input_stats _momentum _eps _cudnn_enabled = unsafePerformIO $ (cast9 ATen.instance_norm_tttttbddb) _input _weight _bias _running_mean _running_var _use_input_stats _momentum _eps _cudnn_enabled

isclose :: Tensor -> Tensor -> Double -> Double -> Bool -> Tensor
isclose _self _other _rtol _atol _equal_nan = unsafePerformIO $ (cast5 ATen.isclose_ttddb) _self _other _rtol _atol _equal_nan

isnan :: Tensor -> Tensor
isnan _self = unsafePerformIO $ (cast1 ATen.isnan_t) _self

is_distributed :: Tensor -> Bool
is_distributed _self = unsafePerformIO $ (cast1 ATen.is_distributed_t) _self

is_floating_point :: Tensor -> Bool
is_floating_point _self = unsafePerformIO $ (cast1 ATen.is_floating_point_t) _self

is_complex :: Tensor -> Bool
is_complex _self = unsafePerformIO $ (cast1 ATen.is_complex_t) _self

is_nonzero :: Tensor -> Bool
is_nonzero _self = unsafePerformIO $ (cast1 ATen.is_nonzero_t) _self

is_same_size :: Tensor -> Tensor -> Bool
is_same_size _self _other = unsafePerformIO $ (cast2 ATen.is_same_size_tt) _self _other

is_signed :: Tensor -> Bool
is_signed _self = unsafePerformIO $ (cast1 ATen.is_signed_t) _self

kl_div :: Tensor -> Tensor -> Int -> Tensor
kl_div _self _target _reduction = unsafePerformIO $ (cast3 ATen.kl_div_ttl) _self _target _reduction

kl_div_backward :: Tensor -> Tensor -> Tensor -> Int -> Tensor
kl_div_backward _grad_output _self _target _reduction = unsafePerformIO $ (cast4 ATen.kl_div_backward_tttl) _grad_output _self _target _reduction

kthvalue :: Tensor -> Int -> Int -> Bool -> (Tensor,Tensor)
kthvalue _self _k _dim _keepdim = unsafePerformIO $ (cast4 ATen.kthvalue_tllb) _self _k _dim _keepdim

layer_norm :: Tensor -> [Int] -> Tensor -> Tensor -> Double -> Bool -> Tensor
layer_norm _input _normalized_shape _weight _bias _eps _cudnn_enable = unsafePerformIO $ (cast6 ATen.layer_norm_tlttdb) _input _normalized_shape _weight _bias _eps _cudnn_enable

native_layer_norm :: Tensor -> Tensor -> Tensor -> Int -> Int -> Double -> (Tensor,Tensor,Tensor)
native_layer_norm _input _weight _bias _M _N _eps = unsafePerformIO $ (cast6 ATen.native_layer_norm_tttlld) _input _weight _bias _M _N _eps

native_layer_norm_backward :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Int -> Int -> (Bool,Bool,Bool) -> (Tensor,Tensor,Tensor)
native_layer_norm_backward _grad_out _input _mean _rstd _weight _M _N _output_mask = unsafePerformIO $ (cast8 ATen.native_layer_norm_backward_tttttlla) _grad_out _input _mean _rstd _weight _M _N _output_mask

native_layer_norm_double_backward :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Int -> Int -> (Bool,Bool,Bool) -> (Tensor,Tensor,Tensor)
native_layer_norm_double_backward _ggI _ggW _ggb _gO _input _mean _rstd _weight _M _N _output_mask = unsafePerformIO $ (cast11 ATen.native_layer_norm_double_backward_ttttttttlla) _ggI _ggW _ggb _gO _input _mean _rstd _weight _M _N _output_mask

linear :: Tensor -> Tensor -> Tensor -> Tensor
linear _input _weight _bias = unsafePerformIO $ (cast3 ATen.linear_ttt) _input _weight _bias

mkldnn_linear :: Tensor -> Tensor -> Tensor -> Tensor
mkldnn_linear _input _weight _bias = unsafePerformIO $ (cast3 ATen.mkldnn_linear_ttt) _input _weight _bias

fbgemm_linear_int8_weight :: Tensor -> Tensor -> Tensor -> Tensor -> Float -> Float -> Tensor -> Tensor
fbgemm_linear_int8_weight _input _weight _packed _col_offsets _weight_scale _weight_zero_point _bias = unsafePerformIO $ (cast7 ATen.fbgemm_linear_int8_weight_ttttsst) _input _weight _packed _col_offsets _weight_scale _weight_zero_point _bias

fbgemm_linear_quantize_weight :: Tensor -> (Tensor,Tensor,Double,Int)
fbgemm_linear_quantize_weight _input = unsafePerformIO $ (cast1 ATen.fbgemm_linear_quantize_weight_t) _input

fbgemm_pack_gemm_matrix_fp16 :: Tensor -> Tensor
fbgemm_pack_gemm_matrix_fp16 _input = unsafePerformIO $ (cast1 ATen.fbgemm_pack_gemm_matrix_fp16_t) _input

fbgemm_linear_fp16_weight :: Tensor -> Tensor -> Tensor -> Tensor
fbgemm_linear_fp16_weight _input _packed_weight _bias = unsafePerformIO $ (cast3 ATen.fbgemm_linear_fp16_weight_ttt) _input _packed_weight _bias

fbgemm_pack_quantized_matrix :: Tensor -> Int -> Int -> Tensor
fbgemm_pack_quantized_matrix _input _K _N = unsafePerformIO $ (cast3 ATen.fbgemm_pack_quantized_matrix_tll) _input _K _N

--fbgemm_is_cpu_supported :: Bool
--fbgemm_is_cpu_supported  = unsafePerformIO $ (cast0 ATen.fbgemm_is_cpu_supported) 

log :: Tensor -> Tensor
log _self = unsafePerformIO $ (cast1 ATen.log_t) _self

logdet :: Tensor -> Tensor
logdet _self = unsafePerformIO $ (cast1 ATen.logdet_t) _self

logsumexp :: Tensor -> Int -> Bool -> Tensor
logsumexp _self _dim _keepdim = unsafePerformIO $ (cast3 ATen.logsumexp_tlb) _self _dim _keepdim

margin_ranking_loss :: Tensor -> Tensor -> Tensor -> Double -> Int -> Tensor
margin_ranking_loss _input1 _input2 _target _margin _reduction = unsafePerformIO $ (cast5 ATen.margin_ranking_loss_tttdl) _input1 _input2 _target _margin _reduction

matrix_power :: Tensor -> Int -> Tensor
matrix_power _self _n = unsafePerformIO $ (cast2 ATen.matrix_power_tl) _self _n

max_values :: Tensor -> Int -> Bool -> Tensor
max_values _self _dim _keepdim = unsafePerformIO $ (cast3 ATen.max_values_tlb) _self _dim _keepdim

max_pool1d_with_indices :: Tensor -> Int -> Int -> Int -> Int -> Bool -> (Tensor,Tensor)
max_pool1d_with_indices _self _kernel_size _stride _padding _dilation _ceil_mode = unsafePerformIO $ (cast6 ATen.max_pool1d_with_indices_tllllb) _self _kernel_size _stride _padding _dilation _ceil_mode

max_pool1d :: Tensor -> Int -> Int -> Int -> Int -> Bool -> Tensor
max_pool1d _self _kernel_size _stride _padding _dilation _ceil_mode = unsafePerformIO $ (cast6 ATen.max_pool1d_tllllb) _self _kernel_size _stride _padding _dilation _ceil_mode

max_pool2d :: Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Bool -> Tensor
max_pool2d _self _kernel_size _stride _padding _dilation _ceil_mode = unsafePerformIO $ (cast6 ATen.max_pool2d_tllllb) _self _kernel_size _stride _padding _dilation _ceil_mode

mkldnn_max_pool2d :: Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Bool -> Tensor
mkldnn_max_pool2d _self _kernel_size _stride _padding _dilation _ceil_mode = unsafePerformIO $ (cast6 ATen.mkldnn_max_pool2d_tllllb) _self _kernel_size _stride _padding _dilation _ceil_mode

quantized_max_pool2d :: Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Tensor
quantized_max_pool2d _self _kernel_size _stride _padding _dilation = unsafePerformIO $ (cast5 ATen.quantized_max_pool2d_tllll) _self _kernel_size _stride _padding _dilation

max_pool3d :: Tensor -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> Bool -> Tensor
max_pool3d _self _kernel_size _stride _padding _dilation _ceil_mode = unsafePerformIO $ (cast6 ATen.max_pool3d_tllllb) _self _kernel_size _stride _padding _dilation _ceil_mode

min_values :: Tensor -> Int -> Bool -> Tensor
min_values _self _dim _keepdim = unsafePerformIO $ (cast3 ATen.min_values_tlb) _self _dim _keepdim

mkldnn_convolution :: Tensor -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Tensor
mkldnn_convolution _self _weight _bias _padding _stride _dilation _groups = unsafePerformIO $ (cast7 ATen.mkldnn_convolution_tttllll) _self _weight _bias _padding _stride _dilation _groups

mkldnn_convolution_backward_input :: [Int] -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Tensor
mkldnn_convolution_backward_input _self_size _grad_output _weight _padding _stride _dilation _groups _bias_defined = unsafePerformIO $ (cast8 ATen.mkldnn_convolution_backward_input_lttllllb) _self_size _grad_output _weight _padding _stride _dilation _groups _bias_defined

mkldnn_convolution_backward_weights :: [Int] -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> (Tensor,Tensor)
mkldnn_convolution_backward_weights _weight_size _grad_output _self _padding _stride _dilation _groups _bias_defined = unsafePerformIO $ (cast8 ATen.mkldnn_convolution_backward_weights_lttllllb) _weight_size _grad_output _self _padding _stride _dilation _groups _bias_defined

mkldnn_convolution_backward :: Tensor -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> (Bool,Bool,Bool) -> (Tensor,Tensor,Tensor)
mkldnn_convolution_backward _self _grad_output _weight _padding _stride _dilation _groups _output_mask = unsafePerformIO $ (cast8 ATen.mkldnn_convolution_backward_tttlllla) _self _grad_output _weight _padding _stride _dilation _groups _output_mask

miopen_batch_norm :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Bool -> Double -> Double -> (Tensor,Tensor,Tensor)
miopen_batch_norm _input _weight _bias _running_mean _running_var _training _exponential_average_factor _epsilon = unsafePerformIO $ (cast8 ATen.miopen_batch_norm_tttttbdd) _input _weight _bias _running_mean _running_var _training _exponential_average_factor _epsilon

miopen_batch_norm_backward :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Double -> (Tensor,Tensor,Tensor)
miopen_batch_norm_backward _input _grad_output _weight _running_mean _running_var _save_mean _save_var _epsilon = unsafePerformIO $ (cast8 ATen.miopen_batch_norm_backward_tttttttd) _input _grad_output _weight _running_mean _running_var _save_mean _save_var _epsilon

miopen_convolution :: Tensor -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> Tensor
miopen_convolution _self _weight _bias _padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (cast9 ATen.miopen_convolution_tttllllbb) _self _weight _bias _padding _stride _dilation _groups _benchmark _deterministic

miopen_convolution_backward_input :: [Int] -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> Tensor
miopen_convolution_backward_input _self_size _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (cast9 ATen.miopen_convolution_backward_input_lttllllbb) _self_size _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic

miopen_convolution_backward :: Tensor -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> (Bool,Bool,Bool) -> (Tensor,Tensor,Tensor)
miopen_convolution_backward _self _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic _output_mask = unsafePerformIO $ (cast10 ATen.miopen_convolution_backward_tttllllbba) _self _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic _output_mask

miopen_convolution_backward_bias :: Tensor -> Tensor
miopen_convolution_backward_bias _grad_output = unsafePerformIO $ (cast1 ATen.miopen_convolution_backward_bias_t) _grad_output

miopen_convolution_backward_weight :: [Int] -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> Tensor
miopen_convolution_backward_weight _weight_size _grad_output _self _padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (cast9 ATen.miopen_convolution_backward_weight_lttllllbb) _weight_size _grad_output _self _padding _stride _dilation _groups _benchmark _deterministic

miopen_convolution_transpose :: Tensor -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> Tensor
miopen_convolution_transpose _self _weight _bias _padding _output_padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (cast10 ATen.miopen_convolution_transpose_tttlllllbb) _self _weight _bias _padding _output_padding _stride _dilation _groups _benchmark _deterministic

miopen_convolution_transpose_backward :: Tensor -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> (Bool,Bool,Bool) -> (Tensor,Tensor,Tensor)
miopen_convolution_transpose_backward _self _grad_output _weight _padding _output_padding _stride _dilation _groups _benchmark _deterministic _output_mask = unsafePerformIO $ (cast11 ATen.miopen_convolution_transpose_backward_tttlllllbba) _self _grad_output _weight _padding _output_padding _stride _dilation _groups _benchmark _deterministic _output_mask

miopen_convolution_transpose_backward_input :: Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> Tensor
miopen_convolution_transpose_backward_input _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (cast8 ATen.miopen_convolution_transpose_backward_input_ttllllbb) _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic

miopen_convolution_transpose_backward_weight :: [Int] -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> Tensor
miopen_convolution_transpose_backward_weight _weight_size _grad_output _self _padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (cast9 ATen.miopen_convolution_transpose_backward_weight_lttllllbb) _weight_size _grad_output _self _padding _stride _dilation _groups _benchmark _deterministic

miopen_depthwise_convolution :: Tensor -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> Tensor
miopen_depthwise_convolution _self _weight _bias _padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (cast9 ATen.miopen_depthwise_convolution_tttllllbb) _self _weight _bias _padding _stride _dilation _groups _benchmark _deterministic

miopen_depthwise_convolution_backward_input :: [Int] -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> Tensor
miopen_depthwise_convolution_backward_input _self_size _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (cast9 ATen.miopen_depthwise_convolution_backward_input_lttllllbb) _self_size _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic

miopen_depthwise_convolution_backward :: Tensor -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> (Bool,Bool,Bool) -> (Tensor,Tensor,Tensor)
miopen_depthwise_convolution_backward _self _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic _output_mask = unsafePerformIO $ (cast10 ATen.miopen_depthwise_convolution_backward_tttllllbba) _self _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic _output_mask

miopen_depthwise_convolution_backward_weight :: [Int] -> Tensor -> Tensor -> [Int] -> [Int] -> [Int] -> Int -> Bool -> Bool -> Tensor
miopen_depthwise_convolution_backward_weight _weight_size _grad_output _self _padding _stride _dilation _groups _benchmark _deterministic = unsafePerformIO $ (cast9 ATen.miopen_depthwise_convolution_backward_weight_lttllllbb) _weight_size _grad_output _self _padding _stride _dilation _groups _benchmark _deterministic

miopen_rnn :: Tensor -> [Tensor] -> Int -> Tensor -> Tensor -> Int -> Int -> Int -> Bool -> Double -> Bool -> Bool -> [Int] -> Tensor -> (Tensor,Tensor,Tensor,Tensor,Tensor)
miopen_rnn _input _weight _weight_stride0 _hx _cx _mode _hidden_size _num_layers _batch_first _dropout _train _bidirectional _batch_sizes _dropout_state = unsafePerformIO $ (cast14 ATen.miopen_rnn_tllttlllbdbblt) _input _weight _weight_stride0 _hx _cx _mode _hidden_size _num_layers _batch_first _dropout _train _bidirectional _batch_sizes _dropout_state

miopen_rnn_backward :: Tensor -> [Tensor] -> Int -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Int -> Int -> Int -> Bool -> Double -> Bool -> Bool -> [Int] -> Tensor -> Tensor -> (Bool,Bool,Bool,Bool) -> (Tensor,Tensor,Tensor,[Tensor])
miopen_rnn_backward _input _weight _weight_stride0 _weight_buf _hx _cx _output _grad_output _grad_hy _grad_cy _mode _hidden_size _num_layers _batch_first _dropout _train _bidirectional _batch_sizes _dropout_state _reserve _output_mask = unsafePerformIO $ (cast21 ATen.miopen_rnn_backward_tlltttttttlllbdbbltta) _input _weight _weight_stride0 _weight_buf _hx _cx _output _grad_output _grad_hy _grad_cy _mode _hidden_size _num_layers _batch_first _dropout _train _bidirectional _batch_sizes _dropout_state _reserve _output_mask

mm :: Tensor -> Tensor -> Tensor
mm _self _mat2 = unsafePerformIO $ (cast2 ATen.mm_tt) _self _mat2

mode :: Tensor -> Int -> Bool -> (Tensor,Tensor)
mode _self _dim _keepdim = unsafePerformIO $ (cast3 ATen.mode_tlb) _self _dim _keepdim

mv :: Tensor -> Tensor -> Tensor
mv _self _vec = unsafePerformIO $ (cast2 ATen.mv_tt) _self _vec

mvlgamma :: Tensor -> Int -> Tensor
mvlgamma _self _p = unsafePerformIO $ (cast2 ATen.mvlgamma_tl) _self _p

narrow :: Tensor -> Int -> Int -> Int -> Tensor
narrow _self _dim _start _length = unsafePerformIO $ (cast4 ATen.narrow_tlll) _self _dim _start _length

native_batch_norm :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Bool -> Double -> Double -> (Tensor,Tensor,Tensor)
native_batch_norm _input _weight _bias _running_mean _running_var _training _momentum _eps = unsafePerformIO $ (cast8 ATen.native_batch_norm_tttttbdd) _input _weight _bias _running_mean _running_var _training _momentum _eps

batch_norm_stats :: Tensor -> Double -> (Tensor,Tensor)
batch_norm_stats _input _eps = unsafePerformIO $ (cast2 ATen.batch_norm_stats_td) _input _eps

batch_norm_elemt :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Double -> Tensor
batch_norm_elemt _input _weight _bias _mean _invstd _eps = unsafePerformIO $ (cast6 ATen.batch_norm_elemt_tttttd) _input _weight _bias _mean _invstd _eps

batch_norm_gather_stats :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Double -> Double -> Int -> (Tensor,Tensor)
batch_norm_gather_stats _input _mean _invstd _running_mean _running_var _momentum _eps _count = unsafePerformIO $ (cast8 ATen.batch_norm_gather_stats_tttttddl) _input _mean _invstd _running_mean _running_var _momentum _eps _count

batch_norm_gather_stats_with_counts :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Double -> Double -> [Int] -> (Tensor,Tensor)
batch_norm_gather_stats_with_counts _input _mean _invstd _running_mean _running_var _momentum _eps _counts = unsafePerformIO $ (cast8 ATen.batch_norm_gather_stats_with_counts_tttttddl) _input _mean _invstd _running_mean _running_var _momentum _eps _counts

native_batch_norm_backward :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Bool -> Double -> (Bool,Bool,Bool) -> (Tensor,Tensor,Tensor)
native_batch_norm_backward _grad_out _input _weight _running_mean _running_var _save_mean _save_invstd _train _eps _output_mask = unsafePerformIO $ (cast10 ATen.native_batch_norm_backward_tttttttbda) _grad_out _input _weight _running_mean _running_var _save_mean _save_invstd _train _eps _output_mask

batch_norm_backward_reduce :: Tensor -> Tensor -> Tensor -> Tensor -> Bool -> Bool -> Bool -> (Tensor,Tensor,Tensor,Tensor)
batch_norm_backward_reduce _grad_out _input _mean _invstd _input_g _weight_g _bias_g = unsafePerformIO $ (cast7 ATen.batch_norm_backward_reduce_ttttbbb) _grad_out _input _mean _invstd _input_g _weight_g _bias_g

batch_norm_backward_elemt :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor
batch_norm_backward_elemt _grad_out _input _mean _invstd _weight _mean_dy _mean_dy_xmu = unsafePerformIO $ (cast7 ATen.batch_norm_backward_elemt_ttttttt) _grad_out _input _mean _invstd _weight _mean_dy _mean_dy_xmu

batch_norm_update_stats :: Tensor -> Tensor -> Tensor -> Double -> (Tensor,Tensor)
batch_norm_update_stats _input _running_mean _running_var _momentum = unsafePerformIO $ (cast4 ATen.batch_norm_update_stats_tttd) _input _running_mean _running_var _momentum

ones_like :: Tensor -> Tensor
ones_like _self = unsafePerformIO $ (cast1 ATen.ones_like_t) _self

pairwise_distance :: Tensor -> Tensor -> Double -> Double -> Bool -> Tensor
pairwise_distance _x1 _x2 _p _eps _keepdim = unsafePerformIO $ (cast5 ATen.pairwise_distance_ttddb) _x1 _x2 _p _eps _keepdim

cdist :: Tensor -> Tensor -> Double -> Tensor
cdist _x1 _x2 _p = unsafePerformIO $ (cast3 ATen.cdist_ttd) _x1 _x2 _p

pdist :: Tensor -> Double -> Tensor
pdist _self _p = unsafePerformIO $ (cast2 ATen.pdist_td) _self _p

cosine_similarity :: Tensor -> Tensor -> Int -> Double -> Tensor
cosine_similarity _x1 _x2 _dim _eps = unsafePerformIO $ (cast4 ATen.cosine_similarity_ttld) _x1 _x2 _dim _eps

pixel_shuffle :: Tensor -> Int -> Tensor
pixel_shuffle _self _upscale_factor = unsafePerformIO $ (cast2 ATen.pixel_shuffle_tl) _self _upscale_factor

pin_memory :: Tensor -> Tensor
pin_memory _self = unsafePerformIO $ (cast1 ATen.pin_memory_t) _self

pinverse :: Tensor -> Double -> Tensor
pinverse _self _rcond = unsafePerformIO $ (cast2 ATen.pinverse_td) _self _rcond

poisson_nll_loss :: Tensor -> Tensor -> Bool -> Bool -> Double -> Int -> Tensor
poisson_nll_loss _input _target _log_input _full _eps _reduction = unsafePerformIO $ (cast6 ATen.poisson_nll_loss_ttbbdl) _input _target _log_input _full _eps _reduction

rand_like :: Tensor -> IO Tensor
rand_like _self = (cast1 ATen.rand_like_t) _self

randn_like :: Tensor -> IO Tensor
randn_like _self = (cast1 ATen.randn_like_t) _self

reciprocal :: Tensor -> Tensor
reciprocal _self = unsafePerformIO $ (cast1 ATen.reciprocal_t) _self

neg :: Tensor -> Tensor
neg _self = unsafePerformIO $ (cast1 ATen.neg_t) _self

round :: Tensor -> Tensor
round _self = unsafePerformIO $ (cast1 ATen.round_t) _self

prelu :: Tensor -> Tensor -> Tensor
prelu _self _weight = unsafePerformIO $ (cast2 ATen.prelu_tt) _self _weight

prelu_backward :: Tensor -> Tensor -> Tensor -> (Tensor,Tensor)
prelu_backward _grad_output _self _weight = unsafePerformIO $ (cast3 ATen.prelu_backward_ttt) _grad_output _self _weight

gelu :: Tensor -> Tensor
gelu _self = unsafePerformIO $ (cast1 ATen.gelu_t) _self

gelu_backward :: Tensor -> Tensor -> Tensor
gelu_backward _grad _self = unsafePerformIO $ (cast2 ATen.gelu_backward_tt) _grad _self

hardshrink :: Tensor -> Float -> Tensor
hardshrink _self _lambd = unsafePerformIO $ (cast2 ATen.hardshrink_ts) _self _lambd

hardshrink_backward :: Tensor -> Tensor -> Float -> Tensor
hardshrink_backward _grad_out _self _lambd = unsafePerformIO $ (cast3 ATen.hardshrink_backward_tts) _grad_out _self _lambd

rsqrt :: Tensor -> Tensor
rsqrt _self = unsafePerformIO $ (cast1 ATen.rsqrt_t) _self

celu :: Tensor -> Float -> Tensor
celu _self _alpha = unsafePerformIO $ (cast2 ATen.celu_ts) _self _alpha

slice :: Tensor -> Int -> Int -> Int -> Int -> Tensor
slice _self _dim _start _end _step = unsafePerformIO $ (cast5 ATen.slice_tllll) _self _dim _start _end _step

slogdet :: Tensor -> (Tensor,Tensor)
slogdet _self = unsafePerformIO $ (cast1 ATen.slogdet_t) _self

smm :: Tensor -> Tensor -> Tensor
smm _self _mat2 = unsafePerformIO $ (cast2 ATen.smm_tt) _self _mat2

split :: Tensor -> Int -> Int -> [Tensor]
split _self _split_size _dim = unsafePerformIO $ (cast3 ATen.split_tll) _self _split_size _dim

split_with_sizes :: Tensor -> [Int] -> Int -> [Tensor]
split_with_sizes _self _split_sizes _dim = unsafePerformIO $ (cast3 ATen.split_with_sizes_tll) _self _split_sizes _dim

sspaddmm :: Tensor -> Tensor -> Tensor -> Float -> Float -> Tensor
sspaddmm _self _mat1 _mat2 _beta _alpha = unsafePerformIO $ (cast5 ATen.sspaddmm_tttss) _self _mat1 _mat2 _beta _alpha

stack :: [Tensor] -> Int -> Tensor
stack _tensors _dim = unsafePerformIO $ (cast2 ATen.stack_ll) _tensors _dim

stft :: Tensor -> Int -> Int -> Int -> Tensor -> Bool -> Bool -> Tensor
stft _self _n_fft _hop_length _win_length _window _normalized _onesided = unsafePerformIO $ (cast7 ATen.stft_tllltbb) _self _n_fft _hop_length _win_length _window _normalized _onesided

stride :: Tensor -> Int -> Int
stride _self _dim = unsafePerformIO $ (cast2 ATen.stride_tl) _self _dim

t :: Tensor -> Tensor
t _self = unsafePerformIO $ (cast1 ATen.t_t) _self

tan :: Tensor -> Tensor
tan _self = unsafePerformIO $ (cast1 ATen.tan_t) _self

tensordot :: Tensor -> Tensor -> [Int] -> [Int] -> Tensor
tensordot _self _other _dims_self _dims_other = unsafePerformIO $ (cast4 ATen.tensordot_ttll) _self _other _dims_self _dims_other

threshold :: Tensor -> Float -> Float -> Tensor
threshold _self _threshold _value = unsafePerformIO $ (cast3 ATen.threshold_tss) _self _threshold _value

threshold_backward :: Tensor -> Tensor -> Float -> Tensor
threshold_backward _grad_output _self _threshold = unsafePerformIO $ (cast3 ATen.threshold_backward_tts) _grad_output _self _threshold

one_hot :: Tensor -> Int -> Tensor
one_hot _self _num_classes = unsafePerformIO $ (cast2 ATen.one_hot_tl) _self _num_classes

flip :: Tensor -> [Int] -> Tensor
flip _self _dims = unsafePerformIO $ (cast2 ATen.flip_tl) _self _dims

roll :: Tensor -> Int -> Int -> Tensor
roll _self _shifts _dims = unsafePerformIO $ (cast3 ATen.roll_tll) _self _shifts _dims

rot90 :: Tensor -> Int -> [Int] -> Tensor
rot90 _self _k _dims = unsafePerformIO $ (cast3 ATen.rot90_tll) _self _k _dims

triplet_margin_loss :: Tensor -> Tensor -> Tensor -> Double -> Double -> Double -> Bool -> Int -> Tensor
triplet_margin_loss _anchor _positive _negative _margin _p _eps _swap _reduction = unsafePerformIO $ (cast8 ATen.triplet_margin_loss_tttdddbl) _anchor _positive _negative _margin _p _eps _swap _reduction

trunc :: Tensor -> Tensor
trunc _self = unsafePerformIO $ (cast1 ATen.trunc_t) _self

unique_dim :: Tensor -> Int -> Bool -> Bool -> Bool -> (Tensor,Tensor,Tensor)
unique_dim _self _dim _sorted _return_inverse _return_counts = unsafePerformIO $ (cast5 ATen.unique_dim_tlbbb) _self _dim _sorted _return_inverse _return_counts

unique_consecutive :: Tensor -> Bool -> Bool -> Int -> (Tensor,Tensor,Tensor)
unique_consecutive _self _return_inverse _return_counts _dim = unsafePerformIO $ (cast4 ATen.unique_consecutive_tbbl) _self _return_inverse _return_counts _dim

unique_dim_consecutive :: Tensor -> Int -> Bool -> Bool -> (Tensor,Tensor,Tensor)
unique_dim_consecutive _self _dim _return_inverse _return_counts = unsafePerformIO $ (cast4 ATen.unique_dim_consecutive_tlbb) _self _dim _return_inverse _return_counts

unsqueeze :: Tensor -> Int -> Tensor
unsqueeze _self _dim = unsafePerformIO $ (cast2 ATen.unsqueeze_tl) _self _dim

where' :: Tensor -> Tensor -> Tensor -> Tensor
where' _condition _self _other = unsafePerformIO $ (cast3 ATen.where_ttt) _condition _self _other

where_ :: Tensor -> [Tensor]
where_ _condition = unsafePerformIO $ (cast1 ATen.where_t) _condition

norm_except_dim :: Tensor -> Int -> Int -> Tensor
norm_except_dim _v _pow _dim = unsafePerformIO $ (cast3 ATen.norm_except_dim_tll) _v _pow _dim

zeros_like :: Tensor -> Tensor
zeros_like _self = unsafePerformIO $ (cast1 ATen.zeros_like_t) _self

native_norm :: Tensor -> Float -> Tensor
native_norm _self _p = unsafePerformIO $ (cast2 ATen.native_norm_ts) _self _p

clone :: Tensor -> Tensor
clone _self = unsafePerformIO $ (cast1 ATen.clone_t) _self

s_native_addmm :: Tensor -> Tensor -> Tensor -> Float -> Float -> Tensor
s_native_addmm _self _mat1 _mat2 _beta _alpha = unsafePerformIO $ (cast5 ATen.s_native_addmm_tttss) _self _mat1 _mat2 _beta _alpha

addmm :: Tensor -> Tensor -> Tensor -> Float -> Float -> Tensor
addmm _self _mat1 _mat2 _beta _alpha = unsafePerformIO $ (cast5 ATen.addmm_tttss) _self _mat1 _mat2 _beta _alpha

to_dense_backward :: Tensor -> Tensor -> Tensor
to_dense_backward _grad _input = unsafePerformIO $ (cast2 ATen.to_dense_backward_tt) _grad _input

hspmm :: Tensor -> Tensor -> Tensor
hspmm _mat1 _mat2 = unsafePerformIO $ (cast2 ATen.hspmm_tt) _mat1 _mat2

numel :: Tensor -> Int
numel _self = unsafePerformIO $ (cast1 ATen.numel_t) _self

unbind :: Tensor -> Int -> [Tensor]
unbind _self _dim = unsafePerformIO $ (cast2 ATen.unbind_tl) _self _dim

mkldnn_reorder_conv2d_weight :: Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Int -> Tensor
mkldnn_reorder_conv2d_weight _self _padding _stride _dilation _groups = unsafePerformIO $ (cast5 ATen.mkldnn_reorder_conv2d_weight_tllll) _self _padding _stride _dilation _groups

to_mkldnn_backward :: Tensor -> Tensor -> Tensor
to_mkldnn_backward _grad _input = unsafePerformIO $ (cast2 ATen.to_mkldnn_backward_tt) _grad _input

--quantize_linear :: Tensor -> Double -> Int -> DType -> Tensor
--quantize_linear _self _scale _zero_point _dtype = unsafePerformIO $ (cast4 ATen.quantize_linear_tdls) _self _scale _zero_point _dtype

--quantize_linear_per_channel :: Tensor -> Tensor -> Tensor -> [Int] -> DType -> Tensor
--quantize_linear_per_channel _self _scales _zero_points _axis _dtype = unsafePerformIO $ (cast5 ATen.quantize_linear_per_channel_tttls) _self _scales _zero_points _axis _dtype

dequantize :: Tensor -> Tensor
dequantize _self = unsafePerformIO $ (cast1 ATen.dequantize_t) _self

q_scale :: Tensor -> Double
q_scale _self = unsafePerformIO $ (cast1 ATen.q_scale_t) _self

q_zero_point :: Tensor -> Int
q_zero_point _self = unsafePerformIO $ (cast1 ATen.q_zero_point_t) _self

int_repr :: Tensor -> Tensor
int_repr _self = unsafePerformIO $ (cast1 ATen.int_repr_t) _self

fake_quantize_per_tensor_affine :: Tensor -> Double -> Int -> Int -> Int -> Tensor
fake_quantize_per_tensor_affine _self _scale _zero_point _quant_min _quant_max = unsafePerformIO $ (cast5 ATen.fake_quantize_per_tensor_affine_tdlll) _self _scale _zero_point _quant_min _quant_max

fake_quantize_per_tensor_affine_backward :: Tensor -> Tensor -> Double -> Int -> Int -> Int -> Tensor
fake_quantize_per_tensor_affine_backward _grad _self _scale _zero_point _quant_min _quant_max = unsafePerformIO $ (cast6 ATen.fake_quantize_per_tensor_affine_backward_ttdlll) _grad _self _scale _zero_point _quant_min _quant_max

meshgrid :: [Tensor] -> [Tensor]
meshgrid _tensors = unsafePerformIO $ (cast1 ATen.meshgrid_l) _tensors

cartesian_prod :: [Tensor] -> Tensor
cartesian_prod _tensors = unsafePerformIO $ (cast1 ATen.cartesian_prod_l) _tensors

combinations :: Tensor -> Int -> Bool -> Tensor
combinations _self _r _with_replacement = unsafePerformIO $ (cast3 ATen.combinations_tlb) _self _r _with_replacement

lstm_cell :: Tensor -> [Tensor] -> Tensor -> Tensor -> Tensor -> Tensor -> (Tensor,Tensor)
lstm_cell _input _hx _w_ih _w_hh _b_ih _b_hh = unsafePerformIO $ (cast6 ATen.lstm_cell_tltttt) _input _hx _w_ih _w_hh _b_ih _b_hh

gru_cell :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor
gru_cell _input _hx _w_ih _w_hh _b_ih _b_hh = unsafePerformIO $ (cast6 ATen.gru_cell_tttttt) _input _hx _w_ih _w_hh _b_ih _b_hh

rnn_tanh_cell :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor
rnn_tanh_cell _input _hx _w_ih _w_hh _b_ih _b_hh = unsafePerformIO $ (cast6 ATen.rnn_tanh_cell_tttttt) _input _hx _w_ih _w_hh _b_ih _b_hh

rnn_relu_cell :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor
rnn_relu_cell _input _hx _w_ih _w_hh _b_ih _b_hh = unsafePerformIO $ (cast6 ATen.rnn_relu_cell_tttttt) _input _hx _w_ih _w_hh _b_ih _b_hh

--quantized_lstm :: Tensor -> [Tensor] -> [Tensor] -> Bool -> Int -> Double -> Bool -> Bool -> Bool -> DType -> (Tensor,Tensor,Tensor)
--quantized_lstm _input _hx _params _has_biases _num_layers _dropout _train _bidirectional _batch_first _dtype = unsafePerformIO $ (cast10 ATen.quantized_lstm_tllbldbbbs) _input _hx _params _has_biases _num_layers _dropout _train _bidirectional _batch_first _dtype

quantized_lstm_cell :: Tensor -> [Tensor] -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Float -> Float -> Float -> Float -> (Tensor,Tensor)
quantized_lstm_cell _input _hx _w_ih _w_hh _b_ih _b_hh _packed_ih _packed_hh _col_offsets_ih _col_offsets_hh _scale_ih _scale_hh _zero_point_ih _zero_point_hh = unsafePerformIO $ (cast14 ATen.quantized_lstm_cell_tlttttttttssss) _input _hx _w_ih _w_hh _b_ih _b_hh _packed_ih _packed_hh _col_offsets_ih _col_offsets_hh _scale_ih _scale_hh _zero_point_ih _zero_point_hh

quantized_gru_cell :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Float -> Float -> Float -> Float -> Tensor
quantized_gru_cell _input _hx _w_ih _w_hh _b_ih _b_hh _packed_ih _packed_hh _col_offsets_ih _col_offsets_hh _scale_ih _scale_hh _zero_point_ih _zero_point_hh = unsafePerformIO $ (cast14 ATen.quantized_gru_cell_ttttttttttssss) _input _hx _w_ih _w_hh _b_ih _b_hh _packed_ih _packed_hh _col_offsets_ih _col_offsets_hh _scale_ih _scale_hh _zero_point_ih _zero_point_hh

quantized_rnn_relu_cell :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Float -> Float -> Float -> Float -> Tensor
quantized_rnn_relu_cell _input _hx _w_ih _w_hh _b_ih _b_hh _packed_ih _packed_hh _col_offsets_ih _col_offsets_hh _scale_ih _scale_hh _zero_point_ih _zero_point_hh = unsafePerformIO $ (cast14 ATen.quantized_rnn_relu_cell_ttttttttttssss) _input _hx _w_ih _w_hh _b_ih _b_hh _packed_ih _packed_hh _col_offsets_ih _col_offsets_hh _scale_ih _scale_hh _zero_point_ih _zero_point_hh

quantized_rnn_tanh_cell :: Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Tensor -> Float -> Float -> Float -> Float -> Tensor
quantized_rnn_tanh_cell _input _hx _w_ih _w_hh _b_ih _b_hh _packed_ih _packed_hh _col_offsets_ih _col_offsets_hh _scale_ih _scale_hh _zero_point_ih _zero_point_hh = unsafePerformIO $ (cast14 ATen.quantized_rnn_tanh_cell_ttttttttttssss) _input _hx _w_ih _w_hh _b_ih _b_hh _packed_ih _packed_hh _col_offsets_ih _col_offsets_hh _scale_ih _scale_hh _zero_point_ih _zero_point_hh

masked_scatter :: Tensor -> Tensor -> Tensor -> Tensor
masked_scatter _self _mask _source = unsafePerformIO $ (cast3 ATen.masked_scatter_ttt) _self _mask _source

index_add :: Tensor -> Int -> Tensor -> Tensor -> Tensor
index_add _self _dim _index _source = unsafePerformIO $ (cast4 ATen.index_add_tltt) _self _dim _index _source

scatter_add :: Tensor -> Int -> Tensor -> Tensor -> Tensor
scatter_add _self _dim _index _src = unsafePerformIO $ (cast4 ATen.scatter_add_tltt) _self _dim _index _src

addbmm :: Tensor -> Tensor -> Tensor -> Float -> Float -> Tensor
addbmm _self _batch1 _batch2 _beta _alpha = unsafePerformIO $ (cast5 ATen.addbmm_tttss) _self _batch1 _batch2 _beta _alpha

cross :: Tensor -> Tensor -> Int -> Tensor
cross _self _other _dim = unsafePerformIO $ (cast3 ATen.cross_ttl) _self _other _dim

triu :: Tensor -> Int -> Tensor
triu _self _diagonal = unsafePerformIO $ (cast2 ATen.triu_tl) _self _diagonal

tril :: Tensor -> Int -> Tensor
tril _self _diagonal = unsafePerformIO $ (cast2 ATen.tril_tl) _self _diagonal

trace :: Tensor -> Tensor
trace _self = unsafePerformIO $ (cast1 ATen.trace_t) _self

take :: Tensor -> Tensor -> Tensor
take _self _index = unsafePerformIO $ (cast2 ATen.take_tt) _self _index

index_select :: Tensor -> Int -> Tensor -> Tensor
index_select _self _dim _index = unsafePerformIO $ (cast3 ATen.index_select_tlt) _self _dim _index

masked_select :: Tensor -> Tensor -> Tensor
masked_select _self _mask = unsafePerformIO $ (cast2 ATen.masked_select_tt) _self _mask

nonzero :: Tensor -> Tensor
nonzero _self = unsafePerformIO $ (cast1 ATen.nonzero_t) _self

nonzero_numpy :: Tensor -> [Tensor]
nonzero_numpy _self = unsafePerformIO $ (cast1 ATen.nonzero_numpy_t) _self

gather :: Tensor -> Int -> Tensor -> Bool -> Tensor
gather _self _dim _index _sparse_grad = unsafePerformIO $ (cast4 ATen.gather_tltb) _self _dim _index _sparse_grad

addcmul :: Tensor -> Tensor -> Tensor -> Float -> Tensor
addcmul _self _tensor1 _tensor2 _value = unsafePerformIO $ (cast4 ATen.addcmul_ttts) _self _tensor1 _tensor2 _value

addcdiv :: Tensor -> Tensor -> Tensor -> Float -> Tensor
addcdiv _self _tensor1 _tensor2 _value = unsafePerformIO $ (cast4 ATen.addcdiv_ttts) _self _tensor1 _tensor2 _value

lstsq :: Tensor -> Tensor -> (Tensor,Tensor)
lstsq _self _A = unsafePerformIO $ (cast2 ATen.lstsq_tt) _self _A

triangular_solve :: Tensor -> Tensor -> Bool -> Bool -> Bool -> (Tensor,Tensor)
triangular_solve _self _A _upper _transpose _unitriangular = unsafePerformIO $ (cast5 ATen.triangular_solve_ttbbb) _self _A _upper _transpose _unitriangular

qr :: Tensor -> Bool -> (Tensor,Tensor)
qr _self _some = unsafePerformIO $ (cast2 ATen.qr_tb) _self _some

ormqr :: Tensor -> Tensor -> Tensor -> Bool -> Bool -> Tensor
ormqr _self _input2 _input3 _left _transpose = unsafePerformIO $ (cast5 ATen.ormqr_tttbb) _self _input2 _input3 _left _transpose

lu_solve :: Tensor -> Tensor -> Tensor -> Tensor
lu_solve _self _LU_data _LU_pivots = unsafePerformIO $ (cast3 ATen.lu_solve_ttt) _self _LU_data _LU_pivots

lgamma :: Tensor -> Tensor
lgamma _self = unsafePerformIO $ (cast1 ATen.lgamma_t) _self

digamma :: Tensor -> Tensor
digamma _self = unsafePerformIO $ (cast1 ATen.digamma_t) _self

polygamma :: Int -> Tensor -> Tensor
polygamma _n _self = unsafePerformIO $ (cast2 ATen.polygamma_lt) _n _self

erfinv :: Tensor -> Tensor
erfinv _self = unsafePerformIO $ (cast1 ATen.erfinv_t) _self

dist :: Tensor -> Tensor -> Float -> Tensor
dist _self _other _p = unsafePerformIO $ (cast3 ATen.dist_tts) _self _other _p

atan2 :: Tensor -> Tensor -> Tensor
atan2 _self _other = unsafePerformIO $ (cast2 ATen.atan2_tt) _self _other

histc :: Tensor -> Int -> Float -> Float -> Tensor
histc _self _bins _min _max = unsafePerformIO $ (cast4 ATen.histc_tlss) _self _bins _min _max

minAll :: Tensor -> Tensor
minAll _self = unsafePerformIO $ (cast1 ATen.min_t) _self

maxAll :: Tensor -> Tensor
maxAll _self = unsafePerformIO $ (cast1 ATen.max_t) _self

medianAll :: Tensor -> Tensor
medianAll _self = unsafePerformIO $ (cast1 ATen.median_t) _self

sort :: Tensor -> Int -> Bool -> (Tensor,Tensor)
sort _self _dim _descending = unsafePerformIO $ (cast3 ATen.sort_tlb) _self _dim _descending

argsort :: Tensor -> Int -> Bool -> Tensor
argsort _self _dim _descending = unsafePerformIO $ (cast3 ATen.argsort_tlb) _self _dim _descending

topk :: Tensor -> Int -> Int -> Bool -> Bool -> (Tensor,Tensor)
topk _self _k _dim _largest _sorted = unsafePerformIO $ (cast5 ATen.topk_tllbb) _self _k _dim _largest _sorted

renorm :: Tensor -> Float -> Int -> Float -> Tensor
renorm _self _p _dim _maxnorm = unsafePerformIO $ (cast4 ATen.renorm_tsls) _self _p _dim _maxnorm

equal :: Tensor -> Tensor -> Bool
equal _self _other = unsafePerformIO $ (cast2 ATen.equal_tt) _self _other

alias :: Tensor -> Tensor
alias _self = unsafePerformIO $ (cast1 ATen.alias_t) _self

binary_cross_entropy :: Tensor -> Tensor -> Tensor -> Int -> Tensor
binary_cross_entropy _self _target _weight _reduction = unsafePerformIO $ (cast4 ATen.binary_cross_entropy_tttl) _self _target _weight _reduction

binary_cross_entropy_backward :: Tensor -> Tensor -> Tensor -> Tensor -> Int -> Tensor
binary_cross_entropy_backward _grad_output _self _target _weight _reduction = unsafePerformIO $ (cast5 ATen.binary_cross_entropy_backward_ttttl) _grad_output _self _target _weight _reduction

mse_loss_backward :: Tensor -> Tensor -> Tensor -> Int -> Tensor
mse_loss_backward _grad_output _self _target _reduction = unsafePerformIO $ (cast4 ATen.mse_loss_backward_tttl) _grad_output _self _target _reduction

l1_loss :: Tensor -> Tensor -> Int -> Tensor
l1_loss _self _target _reduction = unsafePerformIO $ (cast3 ATen.l1_loss_ttl) _self _target _reduction

l1_loss_backward :: Tensor -> Tensor -> Tensor -> Int -> Tensor
l1_loss_backward _grad_output _self _target _reduction = unsafePerformIO $ (cast4 ATen.l1_loss_backward_tttl) _grad_output _self _target _reduction

multi_margin_loss :: Tensor -> Tensor -> Float -> Float -> Tensor -> Int -> Tensor
multi_margin_loss _self _target _p _margin _weight _reduction = unsafePerformIO $ (cast6 ATen.multi_margin_loss_ttsstl) _self _target _p _margin _weight _reduction

multi_margin_loss_backward :: Tensor -> Tensor -> Tensor -> Float -> Float -> Tensor -> Int -> Tensor
multi_margin_loss_backward _grad_output _self _target _p _margin _weight _reduction = unsafePerformIO $ (cast7 ATen.multi_margin_loss_backward_tttsstl) _grad_output _self _target _p _margin _weight _reduction

multilabel_margin_loss :: Tensor -> Tensor -> Int -> Tensor
multilabel_margin_loss _self _target _reduction = unsafePerformIO $ (cast3 ATen.multilabel_margin_loss_ttl) _self _target _reduction

multilabel_margin_loss_forward :: Tensor -> Tensor -> Int -> (Tensor,Tensor)
multilabel_margin_loss_forward _self _target _reduction = unsafePerformIO $ (cast3 ATen.multilabel_margin_loss_forward_ttl) _self _target _reduction

multilabel_margin_loss_backward :: Tensor -> Tensor -> Tensor -> Int -> Tensor -> Tensor
multilabel_margin_loss_backward _grad_output _self _target _reduction _is_target = unsafePerformIO $ (cast5 ATen.multilabel_margin_loss_backward_tttlt) _grad_output _self _target _reduction _is_target

nll_loss :: Tensor -> Tensor -> Tensor -> Int -> Int -> Tensor
nll_loss _self _target _weight _reduction _ignore_index = unsafePerformIO $ (cast5 ATen.nll_loss_tttll) _self _target _weight _reduction _ignore_index

nll_loss_forward :: Tensor -> Tensor -> Tensor -> Int -> Int -> (Tensor,Tensor)
nll_loss_forward _self _target _weight _reduction _ignore_index = unsafePerformIO $ (cast5 ATen.nll_loss_forward_tttll) _self _target _weight _reduction _ignore_index

nll_loss_backward :: Tensor -> Tensor -> Tensor -> Tensor -> Int -> Int -> Tensor -> Tensor
nll_loss_backward _grad_output _self _target _weight _reduction _ignore_index _total_weight = unsafePerformIO $ (cast7 ATen.nll_loss_backward_ttttllt) _grad_output _self _target _weight _reduction _ignore_index _total_weight

nll_loss2d :: Tensor -> Tensor -> Tensor -> Int -> Int -> Tensor
nll_loss2d _self _target _weight _reduction _ignore_index = unsafePerformIO $ (cast5 ATen.nll_loss2d_tttll) _self _target _weight _reduction _ignore_index

nll_loss2d_forward :: Tensor -> Tensor -> Tensor -> Int -> Int -> (Tensor,Tensor)
nll_loss2d_forward _self _target _weight _reduction _ignore_index = unsafePerformIO $ (cast5 ATen.nll_loss2d_forward_tttll) _self _target _weight _reduction _ignore_index

nll_loss2d_backward :: Tensor -> Tensor -> Tensor -> Tensor -> Int -> Int -> Tensor -> Tensor
nll_loss2d_backward _grad_output _self _target _weight _reduction _ignore_index _total_weight = unsafePerformIO $ (cast7 ATen.nll_loss2d_backward_ttttllt) _grad_output _self _target _weight _reduction _ignore_index _total_weight

smooth_l1_loss :: Tensor -> Tensor -> Int -> Tensor
smooth_l1_loss _self _target _reduction = unsafePerformIO $ (cast3 ATen.smooth_l1_loss_ttl) _self _target _reduction

smooth_l1_loss_backward :: Tensor -> Tensor -> Tensor -> Int -> Tensor
smooth_l1_loss_backward _grad_output _self _target _reduction = unsafePerformIO $ (cast4 ATen.smooth_l1_loss_backward_tttl) _grad_output _self _target _reduction

soft_margin_loss :: Tensor -> Tensor -> Int -> Tensor
soft_margin_loss _self _target _reduction = unsafePerformIO $ (cast3 ATen.soft_margin_loss_ttl) _self _target _reduction

soft_margin_loss_backward :: Tensor -> Tensor -> Tensor -> Int -> Tensor
soft_margin_loss_backward _grad_output _self _target _reduction = unsafePerformIO $ (cast4 ATen.soft_margin_loss_backward_tttl) _grad_output _self _target _reduction

elu :: Tensor -> Float -> Float -> Float -> Tensor
elu _self _alpha _scale _input_scale = unsafePerformIO $ (cast4 ATen.elu_tsss) _self _alpha _scale _input_scale

elu_backward :: Tensor -> Float -> Float -> Float -> Tensor -> Tensor
elu_backward _grad_output _alpha _scale _input_scale _output = unsafePerformIO $ (cast5 ATen.elu_backward_tssst) _grad_output _alpha _scale _input_scale _output

glu :: Tensor -> Int -> Tensor
glu _self _dim = unsafePerformIO $ (cast2 ATen.glu_tl) _self _dim

glu_backward :: Tensor -> Tensor -> Int -> Tensor
glu_backward _grad_output _self _dim = unsafePerformIO $ (cast3 ATen.glu_backward_ttl) _grad_output _self _dim

hardtanh :: Tensor -> Float -> Float -> Tensor
hardtanh _self _min_val _max_val = unsafePerformIO $ (cast3 ATen.hardtanh_tss) _self _min_val _max_val

hardtanh_backward :: Tensor -> Tensor -> Float -> Float -> Tensor
hardtanh_backward _grad_output _self _min_val _max_val = unsafePerformIO $ (cast4 ATen.hardtanh_backward_ttss) _grad_output _self _min_val _max_val

leaky_relu :: Tensor -> Float -> Tensor
leaky_relu _self _negative_slope = unsafePerformIO $ (cast2 ATen.leaky_relu_ts) _self _negative_slope

leaky_relu_backward :: Tensor -> Tensor -> Float -> Tensor
leaky_relu_backward _grad_output _self _negative_slope = unsafePerformIO $ (cast3 ATen.leaky_relu_backward_tts) _grad_output _self _negative_slope

log_sigmoid :: Tensor -> Tensor
log_sigmoid _self = unsafePerformIO $ (cast1 ATen.log_sigmoid_t) _self

log_sigmoid_forward :: Tensor -> (Tensor,Tensor)
log_sigmoid_forward _self = unsafePerformIO $ (cast1 ATen.log_sigmoid_forward_t) _self

log_sigmoid_backward :: Tensor -> Tensor -> Tensor -> Tensor
log_sigmoid_backward _grad_output _self _buffer = unsafePerformIO $ (cast3 ATen.log_sigmoid_backward_ttt) _grad_output _self _buffer

rrelu_with_noise_backward :: Tensor -> Tensor -> Tensor -> Float -> Float -> Bool -> Tensor
rrelu_with_noise_backward _grad_output _self _noise _lower _upper _training = unsafePerformIO $ (cast6 ATen.rrelu_with_noise_backward_tttssb) _grad_output _self _noise _lower _upper _training

softplus :: Tensor -> Float -> Float -> Tensor
softplus _self _beta _threshold = unsafePerformIO $ (cast3 ATen.softplus_tss) _self _beta _threshold

softplus_backward :: Tensor -> Tensor -> Float -> Float -> Tensor -> Tensor
softplus_backward _grad_output _self _beta _threshold _output = unsafePerformIO $ (cast5 ATen.softplus_backward_ttsst) _grad_output _self _beta _threshold _output

softshrink :: Tensor -> Float -> Tensor
softshrink _self _lambd = unsafePerformIO $ (cast2 ATen.softshrink_ts) _self _lambd

softshrink_backward :: Tensor -> Tensor -> Float -> Tensor
softshrink_backward _grad_output _self _lambd = unsafePerformIO $ (cast3 ATen.softshrink_backward_tts) _grad_output _self _lambd

adaptive_avg_pool2d :: Tensor -> (Int,Int) -> Tensor
adaptive_avg_pool2d _self _output_size = unsafePerformIO $ (cast2 ATen.adaptive_avg_pool2d_tl) _self _output_size

mkldnn_adaptive_avg_pool2d :: Tensor -> (Int,Int) -> Tensor
mkldnn_adaptive_avg_pool2d _self _output_size = unsafePerformIO $ (cast2 ATen.mkldnn_adaptive_avg_pool2d_tl) _self _output_size

adaptive_avg_pool3d :: Tensor -> (Int,Int,Int) -> Tensor
adaptive_avg_pool3d _self _output_size = unsafePerformIO $ (cast2 ATen.adaptive_avg_pool3d_tl) _self _output_size

adaptive_avg_pool3d_backward :: Tensor -> Tensor -> Tensor
adaptive_avg_pool3d_backward _grad_output _self = unsafePerformIO $ (cast2 ATen.adaptive_avg_pool3d_backward_tt) _grad_output _self

adaptive_max_pool2d :: Tensor -> (Int,Int) -> (Tensor,Tensor)
adaptive_max_pool2d _self _output_size = unsafePerformIO $ (cast2 ATen.adaptive_max_pool2d_tl) _self _output_size

adaptive_max_pool2d_backward :: Tensor -> Tensor -> Tensor -> Tensor
adaptive_max_pool2d_backward _grad_output _self _indices = unsafePerformIO $ (cast3 ATen.adaptive_max_pool2d_backward_ttt) _grad_output _self _indices

adaptive_max_pool3d :: Tensor -> (Int,Int,Int) -> (Tensor,Tensor)
adaptive_max_pool3d _self _output_size = unsafePerformIO $ (cast2 ATen.adaptive_max_pool3d_tl) _self _output_size

adaptive_max_pool3d_backward :: Tensor -> Tensor -> Tensor -> Tensor
adaptive_max_pool3d_backward _grad_output _self _indices = unsafePerformIO $ (cast3 ATen.adaptive_max_pool3d_backward_ttt) _grad_output _self _indices

avg_pool2d :: Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Bool -> Bool -> Int -> Tensor
avg_pool2d _self _kernel_size _stride _padding _ceil_mode _count_include_pad _divisor_override = unsafePerformIO $ (cast7 ATen.avg_pool2d_tlllbbl) _self _kernel_size _stride _padding _ceil_mode _count_include_pad _divisor_override

avg_pool2d_backward :: Tensor -> Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Bool -> Bool -> Int -> Tensor
avg_pool2d_backward _grad_output _self _kernel_size _stride _padding _ceil_mode _count_include_pad _divisor_override = unsafePerformIO $ (cast8 ATen.avg_pool2d_backward_ttlllbbl) _grad_output _self _kernel_size _stride _padding _ceil_mode _count_include_pad _divisor_override

avg_pool3d :: Tensor -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> Bool -> Bool -> Int -> Tensor
avg_pool3d _self _kernel_size _stride _padding _ceil_mode _count_include_pad _divisor_override = unsafePerformIO $ (cast7 ATen.avg_pool3d_tlllbbl) _self _kernel_size _stride _padding _ceil_mode _count_include_pad _divisor_override

avg_pool3d_backward :: Tensor -> Tensor -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> Bool -> Bool -> Int -> Tensor
avg_pool3d_backward _grad_output _self _kernel_size _stride _padding _ceil_mode _count_include_pad _divisor_override = unsafePerformIO $ (cast8 ATen.avg_pool3d_backward_ttlllbbl) _grad_output _self _kernel_size _stride _padding _ceil_mode _count_include_pad _divisor_override

fractional_max_pool2d :: Tensor -> (Int,Int) -> (Int,Int) -> Tensor -> (Tensor,Tensor)
fractional_max_pool2d _self _kernel_size _output_size _random_samples = unsafePerformIO $ (cast4 ATen.fractional_max_pool2d_tllt) _self _kernel_size _output_size _random_samples

fractional_max_pool2d_backward :: Tensor -> Tensor -> (Int,Int) -> (Int,Int) -> Tensor -> Tensor
fractional_max_pool2d_backward _grad_output _self _kernel_size _output_size _indices = unsafePerformIO $ (cast5 ATen.fractional_max_pool2d_backward_ttllt) _grad_output _self _kernel_size _output_size _indices

fractional_max_pool3d :: Tensor -> (Int,Int,Int) -> (Int,Int,Int) -> Tensor -> (Tensor,Tensor)
fractional_max_pool3d _self _kernel_size _output_size _random_samples = unsafePerformIO $ (cast4 ATen.fractional_max_pool3d_tllt) _self _kernel_size _output_size _random_samples

fractional_max_pool3d_backward :: Tensor -> Tensor -> (Int,Int,Int) -> (Int,Int,Int) -> Tensor -> Tensor
fractional_max_pool3d_backward _grad_output _self _kernel_size _output_size _indices = unsafePerformIO $ (cast5 ATen.fractional_max_pool3d_backward_ttllt) _grad_output _self _kernel_size _output_size _indices

max_pool2d_with_indices :: Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Bool -> (Tensor,Tensor)
max_pool2d_with_indices _self _kernel_size _stride _padding _dilation _ceil_mode = unsafePerformIO $ (cast6 ATen.max_pool2d_with_indices_tllllb) _self _kernel_size _stride _padding _dilation _ceil_mode

max_pool2d_with_indices_backward :: Tensor -> Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Bool -> Tensor -> Tensor
max_pool2d_with_indices_backward _grad_output _self _kernel_size _stride _padding _dilation _ceil_mode _indices = unsafePerformIO $ (cast8 ATen.max_pool2d_with_indices_backward_ttllllbt) _grad_output _self _kernel_size _stride _padding _dilation _ceil_mode _indices

max_pool3d_with_indices :: Tensor -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> Bool -> (Tensor,Tensor)
max_pool3d_with_indices _self _kernel_size _stride _padding _dilation _ceil_mode = unsafePerformIO $ (cast6 ATen.max_pool3d_with_indices_tllllb) _self _kernel_size _stride _padding _dilation _ceil_mode

max_pool3d_with_indices_backward :: Tensor -> Tensor -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> Bool -> Tensor -> Tensor
max_pool3d_with_indices_backward _grad_output _self _kernel_size _stride _padding _dilation _ceil_mode _indices = unsafePerformIO $ (cast8 ATen.max_pool3d_with_indices_backward_ttllllbt) _grad_output _self _kernel_size _stride _padding _dilation _ceil_mode _indices

max_unpool2d :: Tensor -> Tensor -> (Int,Int) -> Tensor
max_unpool2d _self _indices _output_size = unsafePerformIO $ (cast3 ATen.max_unpool2d_ttl) _self _indices _output_size

max_unpool2d_backward :: Tensor -> Tensor -> Tensor -> (Int,Int) -> Tensor
max_unpool2d_backward _grad_output _self _indices _output_size = unsafePerformIO $ (cast4 ATen.max_unpool2d_backward_tttl) _grad_output _self _indices _output_size

max_unpool3d :: Tensor -> Tensor -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> Tensor
max_unpool3d _self _indices _output_size _stride _padding = unsafePerformIO $ (cast5 ATen.max_unpool3d_ttlll) _self _indices _output_size _stride _padding

max_unpool3d_backward :: Tensor -> Tensor -> Tensor -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> Tensor
max_unpool3d_backward _grad_output _self _indices _output_size _stride _padding = unsafePerformIO $ (cast6 ATen.max_unpool3d_backward_tttlll) _grad_output _self _indices _output_size _stride _padding

reflection_pad1d :: Tensor -> (Int,Int) -> Tensor
reflection_pad1d _self _padding = unsafePerformIO $ (cast2 ATen.reflection_pad1d_tl) _self _padding

reflection_pad1d_backward :: Tensor -> Tensor -> (Int,Int) -> Tensor
reflection_pad1d_backward _grad_output _self _padding = unsafePerformIO $ (cast3 ATen.reflection_pad1d_backward_ttl) _grad_output _self _padding

reflection_pad2d :: Tensor -> (Int,Int,Int,Int) -> Tensor
reflection_pad2d _self _padding = unsafePerformIO $ (cast2 ATen.reflection_pad2d_tl) _self _padding

reflection_pad2d_backward :: Tensor -> Tensor -> (Int,Int,Int,Int) -> Tensor
reflection_pad2d_backward _grad_output _self _padding = unsafePerformIO $ (cast3 ATen.reflection_pad2d_backward_ttl) _grad_output _self _padding

replication_pad1d :: Tensor -> (Int,Int) -> Tensor
replication_pad1d _self _padding = unsafePerformIO $ (cast2 ATen.replication_pad1d_tl) _self _padding

replication_pad1d_backward :: Tensor -> Tensor -> (Int,Int) -> Tensor
replication_pad1d_backward _grad_output _self _padding = unsafePerformIO $ (cast3 ATen.replication_pad1d_backward_ttl) _grad_output _self _padding

replication_pad2d :: Tensor -> (Int,Int,Int,Int) -> Tensor
replication_pad2d _self _padding = unsafePerformIO $ (cast2 ATen.replication_pad2d_tl) _self _padding

replication_pad2d_backward :: Tensor -> Tensor -> (Int,Int,Int,Int) -> Tensor
replication_pad2d_backward _grad_output _self _padding = unsafePerformIO $ (cast3 ATen.replication_pad2d_backward_ttl) _grad_output _self _padding

replication_pad3d :: Tensor -> (Int,Int,Int,Int,Int,Int) -> Tensor
replication_pad3d _self _padding = unsafePerformIO $ (cast2 ATen.replication_pad3d_tl) _self _padding

replication_pad3d_backward :: Tensor -> Tensor -> (Int,Int,Int,Int,Int,Int) -> Tensor
replication_pad3d_backward _grad_output _self _padding = unsafePerformIO $ (cast3 ATen.replication_pad3d_backward_ttl) _grad_output _self _padding

upsample_linear1d :: Tensor -> Int -> Bool -> Tensor
upsample_linear1d _self _output_size _align_corners = unsafePerformIO $ (cast3 ATen.upsample_linear1d_tlb) _self _output_size _align_corners

upsample_linear1d_backward :: Tensor -> Int -> (Int,Int,Int) -> Bool -> Tensor
upsample_linear1d_backward _grad_output _output_size _input_size _align_corners = unsafePerformIO $ (cast4 ATen.upsample_linear1d_backward_tllb) _grad_output _output_size _input_size _align_corners

upsample_bilinear2d :: Tensor -> (Int,Int) -> Bool -> Tensor
upsample_bilinear2d _self _output_size _align_corners = unsafePerformIO $ (cast3 ATen.upsample_bilinear2d_tlb) _self _output_size _align_corners

upsample_bilinear2d_backward :: Tensor -> (Int,Int) -> (Int,Int,Int,Int) -> Bool -> Tensor
upsample_bilinear2d_backward _grad_output _output_size _input_size _align_corners = unsafePerformIO $ (cast4 ATen.upsample_bilinear2d_backward_tllb) _grad_output _output_size _input_size _align_corners

upsample_bicubic2d :: Tensor -> (Int,Int) -> Bool -> Tensor
upsample_bicubic2d _self _output_size _align_corners = unsafePerformIO $ (cast3 ATen.upsample_bicubic2d_tlb) _self _output_size _align_corners

upsample_bicubic2d_backward :: Tensor -> (Int,Int) -> (Int,Int,Int,Int) -> Bool -> Tensor
upsample_bicubic2d_backward _grad_output _output_size _input_size _align_corners = unsafePerformIO $ (cast4 ATen.upsample_bicubic2d_backward_tllb) _grad_output _output_size _input_size _align_corners

upsample_trilinear3d :: Tensor -> (Int,Int,Int) -> Bool -> Tensor
upsample_trilinear3d _self _output_size _align_corners = unsafePerformIO $ (cast3 ATen.upsample_trilinear3d_tlb) _self _output_size _align_corners

upsample_trilinear3d_backward :: Tensor -> (Int,Int,Int) -> (Int,Int,Int,Int,Int) -> Bool -> Tensor
upsample_trilinear3d_backward _grad_output _output_size _input_size _align_corners = unsafePerformIO $ (cast4 ATen.upsample_trilinear3d_backward_tllb) _grad_output _output_size _input_size _align_corners

upsample_nearest1d :: Tensor -> Int -> Tensor
upsample_nearest1d _self _output_size = unsafePerformIO $ (cast2 ATen.upsample_nearest1d_tl) _self _output_size

upsample_nearest1d_backward :: Tensor -> Int -> (Int,Int,Int) -> Tensor
upsample_nearest1d_backward _grad_output _output_size _input_size = unsafePerformIO $ (cast3 ATen.upsample_nearest1d_backward_tll) _grad_output _output_size _input_size

upsample_nearest2d :: Tensor -> (Int,Int) -> Tensor
upsample_nearest2d _self _output_size = unsafePerformIO $ (cast2 ATen.upsample_nearest2d_tl) _self _output_size

upsample_nearest2d_backward :: Tensor -> (Int,Int) -> (Int,Int,Int,Int) -> Tensor
upsample_nearest2d_backward _grad_output _output_size _input_size = unsafePerformIO $ (cast3 ATen.upsample_nearest2d_backward_tll) _grad_output _output_size _input_size

upsample_nearest3d :: Tensor -> (Int,Int,Int) -> Tensor
upsample_nearest3d _self _output_size = unsafePerformIO $ (cast2 ATen.upsample_nearest3d_tl) _self _output_size

upsample_nearest3d_backward :: Tensor -> (Int,Int,Int) -> (Int,Int,Int,Int,Int) -> Tensor
upsample_nearest3d_backward _grad_output _output_size _input_size = unsafePerformIO $ (cast3 ATen.upsample_nearest3d_backward_tll) _grad_output _output_size _input_size

sigmoid_backward :: Tensor -> Tensor -> Tensor
sigmoid_backward _grad_output _output = unsafePerformIO $ (cast2 ATen.sigmoid_backward_tt) _grad_output _output

tanh_backward :: Tensor -> Tensor -> Tensor
tanh_backward _grad_output _output = unsafePerformIO $ (cast2 ATen.tanh_backward_tt) _grad_output _output

conv_transpose2d_backward :: Tensor -> Tensor -> Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Tensor -> Tensor -> (Bool,Bool,Bool) -> (Tensor,Tensor,Tensor)
conv_transpose2d_backward _grad_output _self _weight _kernel_size _stride _padding _output_padding _dilation _columns _ones _output_mask = unsafePerformIO $ (cast11 ATen.conv_transpose2d_backward_tttllllltta) _grad_output _self _weight _kernel_size _stride _padding _output_padding _dilation _columns _ones _output_mask

conv_transpose3d_backward :: Tensor -> Tensor -> Tensor -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> Tensor -> Tensor -> (Bool,Bool,Bool) -> (Tensor,Tensor,Tensor)
conv_transpose3d_backward _grad_output _self _weight _kernel_size _stride _padding _output_padding _dilation _finput _fgrad_input _output_mask = unsafePerformIO $ (cast11 ATen.conv_transpose3d_backward_tttllllltta) _grad_output _self _weight _kernel_size _stride _padding _output_padding _dilation _finput _fgrad_input _output_mask

thnn_conv2d :: Tensor -> Tensor -> (Int,Int) -> Tensor -> (Int,Int) -> (Int,Int) -> Tensor
thnn_conv2d _self _weight _kernel_size _bias _stride _padding = unsafePerformIO $ (cast6 ATen.thnn_conv2d_ttltll) _self _weight _kernel_size _bias _stride _padding

thnn_conv2d_forward :: Tensor -> Tensor -> (Int,Int) -> Tensor -> (Int,Int) -> (Int,Int) -> (Tensor,Tensor,Tensor)
thnn_conv2d_forward _self _weight _kernel_size _bias _stride _padding = unsafePerformIO $ (cast6 ATen.thnn_conv2d_forward_ttltll) _self _weight _kernel_size _bias _stride _padding

thnn_conv2d_backward :: Tensor -> Tensor -> Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Tensor -> Tensor -> (Bool,Bool,Bool) -> (Tensor,Tensor,Tensor)
thnn_conv2d_backward _grad_output _self _weight _kernel_size _stride _padding _finput _fgrad_input _output_mask = unsafePerformIO $ (cast9 ATen.thnn_conv2d_backward_tttllltta) _grad_output _self _weight _kernel_size _stride _padding _finput _fgrad_input _output_mask

thnn_conv_depthwise2d :: Tensor -> Tensor -> (Int,Int) -> Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Tensor
thnn_conv_depthwise2d _self _weight _kernel_size _bias _stride _padding _dilation = unsafePerformIO $ (cast7 ATen.thnn_conv_depthwise2d_ttltlll) _self _weight _kernel_size _bias _stride _padding _dilation

thnn_conv_depthwise2d_forward :: Tensor -> Tensor -> (Int,Int) -> Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Tensor
thnn_conv_depthwise2d_forward _self _weight _kernel_size _bias _stride _padding _dilation = unsafePerformIO $ (cast7 ATen.thnn_conv_depthwise2d_forward_ttltlll) _self _weight _kernel_size _bias _stride _padding _dilation

thnn_conv_depthwise2d_backward :: Tensor -> Tensor -> Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Bool,Bool) -> (Tensor,Tensor)
thnn_conv_depthwise2d_backward _grad_output _self _weight _kernel_size _stride _padding _dilation _output_mask = unsafePerformIO $ (cast8 ATen.thnn_conv_depthwise2d_backward_tttlllla) _grad_output _self _weight _kernel_size _stride _padding _dilation _output_mask

thnn_conv3d :: Tensor -> Tensor -> (Int,Int,Int) -> Tensor -> (Int,Int,Int) -> (Int,Int,Int) -> Tensor
thnn_conv3d _self _weight _kernel_size _bias _stride _padding = unsafePerformIO $ (cast6 ATen.thnn_conv3d_ttltll) _self _weight _kernel_size _bias _stride _padding

thnn_conv3d_forward :: Tensor -> Tensor -> (Int,Int,Int) -> Tensor -> (Int,Int,Int) -> (Int,Int,Int) -> (Tensor,Tensor,Tensor)
thnn_conv3d_forward _self _weight _kernel_size _bias _stride _padding = unsafePerformIO $ (cast6 ATen.thnn_conv3d_forward_ttltll) _self _weight _kernel_size _bias _stride _padding

thnn_conv3d_backward :: Tensor -> Tensor -> Tensor -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> Tensor -> Tensor -> (Bool,Bool,Bool) -> (Tensor,Tensor,Tensor)
thnn_conv3d_backward _grad_output _self _weight _kernel_size _stride _padding _finput _fgrad_input _output_mask = unsafePerformIO $ (cast9 ATen.thnn_conv3d_backward_tttllltta) _grad_output _self _weight _kernel_size _stride _padding _finput _fgrad_input _output_mask

conv_dilated2d :: Tensor -> Tensor -> (Int,Int) -> Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Tensor
conv_dilated2d _self _weight _kernel_size _bias _stride _padding _dilation = unsafePerformIO $ (cast7 ATen.conv_dilated2d_ttltlll) _self _weight _kernel_size _bias _stride _padding _dilation

conv_dilated2d_backward :: Tensor -> Tensor -> Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Bool,Bool,Bool) -> (Tensor,Tensor,Tensor)
conv_dilated2d_backward _grad_output _self _weight _kernel_size _stride _padding _dilation _output_mask = unsafePerformIO $ (cast8 ATen.conv_dilated2d_backward_tttlllla) _grad_output _self _weight _kernel_size _stride _padding _dilation _output_mask

conv_dilated3d :: Tensor -> Tensor -> (Int,Int,Int) -> Tensor -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> Tensor
conv_dilated3d _self _weight _kernel_size _bias _stride _padding _dilation = unsafePerformIO $ (cast7 ATen.conv_dilated3d_ttltlll) _self _weight _kernel_size _bias _stride _padding _dilation

conv_dilated3d_backward :: Tensor -> Tensor -> Tensor -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> (Int,Int,Int) -> (Bool,Bool,Bool) -> (Tensor,Tensor,Tensor)
conv_dilated3d_backward _grad_output _self _weight _kernel_size _stride _padding _dilation _output_mask = unsafePerformIO $ (cast8 ATen.conv_dilated3d_backward_tttlllla) _grad_output _self _weight _kernel_size _stride _padding _dilation _output_mask

col2im :: Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Tensor
col2im _self _output_size _kernel_size _dilation _padding _stride = unsafePerformIO $ (cast6 ATen.col2im_tlllll) _self _output_size _kernel_size _dilation _padding _stride

col2im_backward :: Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Tensor
col2im_backward _grad_output _kernel_size _dilation _padding _stride = unsafePerformIO $ (cast5 ATen.col2im_backward_tllll) _grad_output _kernel_size _dilation _padding _stride

im2col :: Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Tensor
im2col _self _kernel_size _dilation _padding _stride = unsafePerformIO $ (cast5 ATen.im2col_tllll) _self _kernel_size _dilation _padding _stride

im2col_backward :: Tensor -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Int,Int) -> (Int,Int) -> Tensor
im2col_backward _grad_output _input_size _kernel_size _dilation _padding _stride = unsafePerformIO $ (cast6 ATen.im2col_backward_tlllll) _grad_output _input_size _kernel_size _dilation _padding _stride

